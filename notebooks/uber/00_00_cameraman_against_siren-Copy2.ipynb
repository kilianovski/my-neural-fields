{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1b9324-a944-44c3-acc6-a3bfb00462d2",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc00f12-42e4-4e7d-8d8e-49a05c7dd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cc0764-ce24-413d-a372-66426ced8a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7a10ad-1ffd-49f6-8cfe-fd1afef77251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d231dd33-f10a-4a50-8479-b05e1dcd36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74778558-24de-45d9-a08c-d260c015151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from prettytable import PrettyTable\n",
    "except:\n",
    "    ! pip install -q prettytable\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params} type {type(model)}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029ca338-c19e-4ae3-9582-65e5d935a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    pil_img = Image.fromarray(skimage.data.camera())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(pil_img)\n",
    "    return img, pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8cb227e-123e-4d6c-be3a-0199b9680009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img, pil_img = get_cameraman_tensor(sidelength)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "        self.pil_img = pil_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        if idx > 0: raise IndexError\n",
    "            \n",
    "        return self.coords, self.pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26515ff-a3db-4b63-988a-26bd004eafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce37ed9f-4787-430c-b4a2-d35932d9dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_and_psnr(im_a, im_b, data_range=1): \n",
    "    data_range = 1.\n",
    "    mse = F.mse_loss(im_a, im_b)\n",
    "    psnr = 10 * torch.log10((data_range ** 2) / mse)\n",
    "    return mse, psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dcc3cd-b272-4010-b7cd-6cf2cafd470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "cameraman = ImageFitting(256)\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed1c5534-03b8-4c65-bbc0-e3920e3b5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to01(t):\n",
    "    t = t - t.min()\n",
    "    t = t / t.max()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff699e-b8b9-41bd-ac08-ee732ca9e8bc",
   "metadata": {},
   "source": [
    "# Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ce7256-9716-4cc1-94dd-543e2f7bca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2pil(t):\n",
    "    return Image.fromarray((t.detach().cpu().clip(0, 1).numpy()*255).astype(np.uint8))\n",
    "\n",
    "def pil2tensor(pil): return torch.tensor(\n",
    "    np.asarray(pil).astype(np.float32)/255).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "def imagify_tensor(t): \n",
    "    return to01(t).cpu().view(256,256).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c49c19e-e978-45e0-8570-c874c31d3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, cfg):\n",
    "    device = cfg['device']\n",
    "    model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    total_steps = cfg['total_steps']\n",
    "    steps_til_summary = cfg['steps_til_summary']\n",
    "\n",
    "    if cfg.get('use_wandb'):\n",
    "        import wandb\n",
    "        wandb.init(project=cfg['project'], name=cfg['experiment_name'], config=cfg)\n",
    "        \n",
    "    total_params = count_parameters(model)\n",
    "\n",
    "    if cfg.get('use_wandb'):\n",
    "        wandb.log({'total_params': total_params})\n",
    "\n",
    "    optim = torch.optim.Adam(lr=cfg['lr'], params=model.parameters())\n",
    "\n",
    "    model_input, ground_truth = next(iter(dataloader))\n",
    "    model_input, ground_truth = model_input.to(device), ground_truth.to(device)\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        model_output, coords = model(model_input)\n",
    "        mse, psnr = mse_and_psnr(model_output, ground_truth)\n",
    "        loss = mse\n",
    "\n",
    "        if cfg.get('use_wandb'):\n",
    "            wandb.log({'step': step, 'mse': mse.item(), 'psnr': psnr.item()})\n",
    "\n",
    "        if not step % steps_til_summary:\n",
    "            print(f\"Step {step}, Total loss {loss:0.6f}\")\n",
    "            img_grad_tensor = gradient(model_output, coords)\n",
    "            img_laplacian_tensor = laplace(model_output, coords)\n",
    "\n",
    "            img = imagify_tensor(model_output)\n",
    "            img_grad = imagify_tensor(img_grad_tensor.norm(dim=-1))\n",
    "            img_laplacian = imagify_tensor(img_laplacian_tensor)\n",
    "\n",
    "            colage = tensor2pil(torch.cat([img, img_grad, img_laplacian], dim=1))\n",
    "            plt.imshow(colage)\n",
    "            plt.show()\n",
    "\n",
    "            if cfg.get('use_wandb'):\n",
    "                wandb.log({'step': step, 'image': wandb.Image(colage)})\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20de8e7-c376-4a65-92ad-f953fd11d734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070c1514-5ffa-47d4-bfb9-19fb0cd46313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UberLayer(nn.Module):\n",
    "    def __init__(self, input_dim, h=32):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, h*4)\n",
    "        self.h = h\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.h\n",
    "        o = self.linear(x)\n",
    "        o = o[..., :h].sigmoid() * o[..., h:2*h].tanh() * o[..., 2*h:3*h].sin() * o[..., 3*h:4*h].cos()\n",
    "        return o\n",
    "\n",
    "\n",
    "class UberNet(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "  \n",
    "        self.net += [UberLayer(in_features, hidden_features)]\n",
    "        self.net += [UberLayer(hidden_features, hidden_features) for _ in range(hidden_layers)]\n",
    "        self.net += [UberLayer(hidden_features, out_features)]\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords\n",
    "    \n",
    "    \n",
    "# ! pip install random-fourier-features-pytorch\n",
    "import rff\n",
    "class UberNetWithEncoding(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, encoded_size, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "  \n",
    "        self.net += [UberLayer(encoded_size*2, hidden_features)]\n",
    "        self.net += [UberLayer(hidden_features, hidden_features) for _ in range(hidden_layers)]\n",
    "        self.net += [UberLayer(hidden_features, out_features)]\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        \n",
    "        self.encoding = rff.layers.GaussianEncoding(sigma=10.0, input_size=2, encoded_size=encoded_size)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        i = self.encoding(coords)\n",
    "        output = self.net(i)\n",
    "        return output, coords    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4164ee30-9af6-4b62-9320-aaf32e6b25ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/tmp/ipykernel_443462/668683560.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f29e2-7a7e-4e22-9421-529642c48d67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cbae0-6d29-4d47-8323-07d5c7b53672",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "\n",
    "cfg['total_steps'] = 500\n",
    "cfg['steps_til_summary'] = 100\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'siren_baseline'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 256,\n",
    "    'hidden_layers': 3,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = Siren(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbbdc8-d69e-40d1-b790-3af340b17ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'siren_baseline'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 256,\n",
    "    'hidden_layers': 3,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = Siren(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49960d8b-e674-4637-871c-95bf8edd79f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44804b63-782d-484e-b4ba-6f3eb97f35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        # self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d28de-1540-49af-8124-073bd6ceb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'siren_no_init'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 256,\n",
    "    'hidden_layers': 3,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = Siren(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d258ef-82ad-4c7a-967c-4e3f6785c0a9",
   "metadata": {},
   "source": [
    "# uber inr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf19c7a-d873-4ae2-928a-6bf45e15418b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'U' from 'splitnet' (/home/jupyter/src/my-neural-fields/notebooks/uber/splitnet.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_443462/2487346884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msplitnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSplitNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplitNetManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'U' from 'splitnet' (/home/jupyter/src/my-neural-fields/notebooks/uber/splitnet.py)"
     ]
    }
   ],
   "source": [
    "from splitnet import SplitNet, SplitNetManager, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea14b52b-199c-4c4b-ba67-37b96fa0020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def U(*shape):\n",
    "    x = torch.rand(*shape)\n",
    "    x = (x-0.5)*2.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec6026d1-a83e-470e-8ca7-2b126f575658",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:0'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'splitnet_man'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 32,\n",
    "    'hidden_layers': 6,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = SplitNet(**cfg['model_kwargs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36bf9663-498c-4cda-af06-83baf6ebfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "man = SplitNetManager(model)\n",
    "man.init_01(U(5_000, 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3477bcf7-2dcd-4312-b30c-9b9b65ca14d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkilianovski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/src/my-neural-fields/notebooks/uber/wandb/run-20230424_171048-eytu5g4w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/uber_inr/runs/eytu5g4w' target=\"_blank\">splitnet_man</a></strong> to <a href='https://wandb.ai/kilianovski/uber_inr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/uber_inr' target=\"_blank\">https://wandb.ai/kilianovski/uber_inr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/uber_inr/runs/eytu5g4w' target=\"_blank\">https://wandb.ai/kilianovski/uber_inr/runs/eytu5g4w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "| net.0.linear.weight |    256     |\n",
      "|  net.0.linear.bias  |    128     |\n",
      "| net.1.linear.weight |    4096    |\n",
      "|  net.1.linear.bias  |    128     |\n",
      "| net.2.linear.weight |    4096    |\n",
      "|  net.2.linear.bias  |    128     |\n",
      "| net.3.linear.weight |    4096    |\n",
      "|  net.3.linear.bias  |    128     |\n",
      "| net.4.linear.weight |    4096    |\n",
      "|  net.4.linear.bias  |    128     |\n",
      "| net.5.linear.weight |    4096    |\n",
      "|  net.5.linear.bias  |    128     |\n",
      "| net.6.linear.weight |    4096    |\n",
      "|  net.6.linear.bias  |    128     |\n",
      "|     net.7.weight    |     32     |\n",
      "|      net.7.bias     |     1      |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 25761 type <class 'splitnet.SplitNet'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_443462/4186522916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/ipykernel_443462/4007141838.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, cfg)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_and_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: - 0.004 MB of 0.020 MB uploaded (0.000 MB deduped)\n",
      "wandb: Run history:\n",
      "wandb: total_params ‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb: total_params 25761\n",
      "wandb: \n",
      "wandb: üöÄ View run splitnet_man at: https://wandb.ai/kilianovski/uber_inr/runs/eytu5g4w\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230424_171048-eytu5g4w/logs\n"
     ]
    }
   ],
   "source": [
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d5f3b-67a6-4ee4-a126-17f946af1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X = torch.randn((256, 256, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a4637-e114-4cb4-8ebe-5e9fc74af446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b953071-1e92-42ba-873c-e769b007ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'ubernet_posenc'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 32,\n",
    "    'hidden_layers': 6,\n",
    "    'encoded_size': 64,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = UberNetWithEncoding(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67eed2-7401-441c-b409-960940f6af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'ubernet_posenc'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 64,\n",
    "    'hidden_layers': 3,\n",
    "    'encoded_size': 64,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = UberNetWithEncoding(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea9878-5125-478b-bbce-c6b756ddaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'ubernet_posenc_micro'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 64,\n",
    "    'hidden_layers': 1,\n",
    "    'encoded_size': 64,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = UberNetWithEncoding(**cfg['model_kwargs'])\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ffa7a-5a02-47f2-bca8-fd3e8c86400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'ubernet_posenc_micro_128'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 128,\n",
    "    'hidden_layers': 1,\n",
    "    'encoded_size': 64,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = UberNetWithEncoding(**cfg['model_kwargs'])\n",
    "count_parameters(model)\n",
    "breakk()\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5e167-15fa-4f68-b5a0-10e2d8d30abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['device'] = 'cuda:3'\n",
    "cfg['lr'] = 1e-4\n",
    "cfg['seed'] = 0\n",
    "\n",
    "cfg['total_steps'] = 10_000\n",
    "cfg['steps_til_summary'] = 1000\n",
    "cfg['project'] = 'uber_inr'\n",
    "cfg['experiment_name'] = 'ubernet_posenc_2_layers'\n",
    "cfg['use_wandb'] = True\n",
    "\n",
    "cfg['model_kwargs'] = {\n",
    "    'in_features': 2,\n",
    "    'out_features': 1,\n",
    "    'hidden_features': 128,\n",
    "    'hidden_layers': 0,\n",
    "    'encoded_size': 64,\n",
    "    'outermost_linear': True,\n",
    "}\n",
    "\n",
    "seed_all(cfg.get('seed', 0))\n",
    "model = UberNetWithEncoding(**cfg['model_kwargs'])\n",
    "count_parameters(model)\n",
    "breakk()\n",
    "train(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05dca8-8fdd-4e3d-86c8-8cbb774a257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def print_model_shape(model, input_shape):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        x = torch.rand(input_shape)\n",
    "        print(f\"{'Layer Name':<30} {'Input Shape':<20} {'Output Shape':<20}\")\n",
    "        print(\"-\" * 70)\n",
    "        for name, layer in model.named_modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                print(f\"{name:<30} {str(x.shape):<20} {str(x.shape):<20}\")\n",
    "\n",
    "# Example usage\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512 * 7 * 7, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 10)\n",
    ")\n",
    "\n",
    "print_model_shape(model, (1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ddbf-5a00-44a9-aced-a06323d960e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
