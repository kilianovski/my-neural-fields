{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74377820-a7bc-4260-8cbc-90a861899b0b",
   "metadata": {},
   "source": [
    "# Define sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776ec5c2-a192-486c-85b9-7ffc4c9e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af749272-b418-4083-9e8b-744eaa51b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'splitnet_lsuv_sweep_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5be134-76e3-4dee-8948-5a77d014476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsuv_m_range = {'min': 0.1, 'max': 2.}\n",
    "\n",
    "# 2: Define the search space\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'metric': \n",
    "    {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'last_psnr'\n",
    "        },\n",
    "    'parameters': \n",
    "    {\n",
    "        'lsuv_m_0': lsuv_m_range,\n",
    "        'lsuv_m_1': lsuv_m_range,\n",
    "        'lsuv_m_2': lsuv_m_range,\n",
    "        'lsuv_m_3': lsuv_m_range,\n",
    "        'm': {'min': 12., 'max': 25.},\n",
    "     }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81df5583-092f-47ca-9e16-a086b5917899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(\n",
    "#     sweep=sweep_configuration,\n",
    "#     project=project_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff2853-1cfd-4056-b178-17cce7a647fe",
   "metadata": {},
   "source": [
    "# Define worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6dfad7d-7801-41d7-9f94-2efc47457810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "# Orthonorm init code is taked from Lasagne\n",
    "# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\n",
    "def svd_orthonormal(w):\n",
    "    shape = w.shape\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    # print (shape, flat_shape)\n",
    "    q = q.reshape(shape)\n",
    "    return q.astype(np.float32)\n",
    "\n",
    "\n",
    "def orthogonal_weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        if hasattr(m, 'weight'):\n",
    "            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n",
    "            m.weight.data = torch.from_numpy(w_ortho)\n",
    "            try:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            #nn.init.orthogonal(m.weight)\n",
    "            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n",
    "            #print w_ortho \n",
    "            #m.weight.data.copy_(torch.from_numpy(w_ortho))\n",
    "            m.weight.data = torch.from_numpy(w_ortho)\n",
    "            try:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            except:\n",
    "                pass\n",
    "    return\n",
    "\n",
    "\n",
    "def splitnet_lsuv_init(self, batch_x, multipliers=(1,1.,1.,1), verbose=True):\n",
    "    device = batch_x.device\n",
    "    self = self.apply(orthogonal_weights_init)\n",
    "    self = self.to(device)\n",
    "\n",
    "    batch_x = self.encoding(batch_x)\n",
    "\n",
    "    net = self.networks[0].net\n",
    "\n",
    "    h = batch_x\n",
    "    for layer in net:\n",
    "        out, acts = layer.forward_with_activations(h)\n",
    "\n",
    "        if True:\n",
    "            if verbose:\n",
    "                print('*'*40)\n",
    "                print('Working with layer', layer)\n",
    "            x, preact, preact_tanh, preact_sigmoid, preact_sin, preact_cos, act_tanh, act_sigmoid, act_sin, act_cos = acts\n",
    "\n",
    "            shape = layer.linear.weight.data.shape[0]//4\n",
    "            # print(layer.linear.weight.data.shape)\n",
    "            for i, preact in enumerate([preact_tanh, preact_sigmoid, preact_sin, preact_cos]):\n",
    "                if verbose:\n",
    "                    print('Initial preact:', preact)\n",
    "                from_i, to_i = i*shape, (i+1)*shape\n",
    "                # W = layer.linear.weight.data[]\n",
    "\n",
    "                mean = preact.mean().item()\n",
    "                std = preact.std().item()\n",
    "\n",
    "                layer.linear.bias.data[from_i:to_i] -= mean\n",
    "                layer.linear.weight.data[from_i:to_i] /= std\n",
    "\n",
    "                layer.linear.weight.data[from_i:to_i] *= multipliers[i]\n",
    "                # print('from_i:to_i', from_i, to_i)\n",
    "                # out, acts = layer.forward_with_activations(h)\n",
    "                # x, preact, preact_tanh, preact_sigmoid, preact_sin, preact_cos, act_tanh, act_sigmoid, act_sin, act_cos = acts\n",
    "\n",
    "            out, acts = layer.forward_with_activations(h)\n",
    "            x, preact, preact_tanh, preact_sigmoid, preact_sin, preact_cos, act_tanh, act_sigmoid, act_sin, act_cos = acts\n",
    "            for i, preact in enumerate([preact_tanh, preact_sigmoid, preact_sin, preact_cos]):\n",
    "                if verbose:\n",
    "                    print('After   preact:', preact)\n",
    "\n",
    "\n",
    "        h = out\n",
    "        \n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f608e17-fffd-4edd-a1c0-b228d02a3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a0dfe3-813b-4223-96d1-3ca2d8d6b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _custom_train_seed(model, cfg, random_seed=0):\n",
    "    seed_all(random_seed)\n",
    "    print(\"Setting seed to\", random_seed)\n",
    "\n",
    "    logger = instantiate(\n",
    "        cfg.logging.logger,\n",
    "        project='эє',\n",
    "        group=cfg.logging.experiment_name,\n",
    "        name=f\"rs{random_seed}\",\n",
    "    )\n",
    "    print(\"*\" * 80)\n",
    "    print(\"\\n\")\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "    print()\n",
    "    print(\"*\" * 80)\n",
    "\n",
    "    device = cfg[\"device\"]\n",
    "\n",
    "    total_steps = cfg[\"total_steps\"]\n",
    "    steps_til_summary = cfg.logging[\"steps_till_summary\"]\n",
    "    batch_size = cfg.get('batch_size', None)\n",
    "\n",
    "    best_psnr = 0\n",
    "    optimizer = instantiate(cfg.optimizer, params=model.parameters())\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        if batch_size:\n",
    "            idxs = torch.randint(0, model_input.shape[1], (batch_size,))\n",
    "            model_input_batch = model_input[:, idxs]\n",
    "            ground_truth_batch = ground_truth[:, idxs]\n",
    "        else:\n",
    "            model_input_batch = model_input\n",
    "            ground_truth_batch = ground_truth\n",
    "\n",
    "        model_output_batch = model(model_input_batch)\n",
    "        mse, psnr = mse_and_psnr(model_output_batch, ground_truth_batch)\n",
    "        loss = mse\n",
    "\n",
    "        psnr = psnr\n",
    "\n",
    "        if best_psnr < psnr:\n",
    "            best_psnr = psnr\n",
    "        log_dic = {\"step\": step, \"mse\": mse.item(), \"psnr\": psnr.item()}\n",
    "        logger.log_dict(log_dic)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(step)\n",
    "\n",
    "    return model, best_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fa7294-38f8-4bf3-b844-a45c4bf89d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "def load_cfg(overrides=()):\n",
    "    # with initialize_config_dir(config_dir=\"/app/notebooks/draft_02/conf\"):\n",
    "    with initialize(version_base=None, config_path=\"./conf\"):\n",
    "        cfg = compose(config_name='config', overrides=list(overrides))\n",
    "        return cfg\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070401e1-92d8-49b7-b151-c5e10b9c54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "project_name = 'splitnet_lsuv_sweep_3'\n",
    "sweep_id = 'kilianovski/splitnet_lsuv_sweep_3/3hhbbojv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b90b33-3c79-45e4-8e6e-4fa4fc2aa8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# global\n",
    "cfg = load_cfg(overrides=[\n",
    "    \"+exp=07_splitnet_lsuv\",\n",
    "    \"random_seed=[0]\",\n",
    "    'logging.logger._target_=spellbook.logging.wandb.WandbLogger',\n",
    "    # \"model.model_configs=[{'hidden_layers': [32, 32]}]\",\n",
    "    \"image=cameraman\",\n",
    "    \"+device=cuda:0\",\n",
    "])\n",
    "\n",
    "device = cfg[\"device\"]\n",
    "\n",
    "model_input, ground_truth, H, W = load_data(cfg)\n",
    "model_input, ground_truth = model_input.to(device), ground_truth.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690a4b01-d780-43b6-b4bc-3020a0d56981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce8dde3-872e-463c-8419-fa0a6eaa33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_for_sweep():\n",
    "    clear_output()\n",
    "    # params\n",
    "    wandb.init(project=project_name)\n",
    "    wandb_cfg = wandb.config\n",
    "    m = wandb_cfg.m\n",
    "    lsuv_multipliers = (wandb_cfg.lsuv_m_0, wandb_cfg.lsuv_m_1, wandb_cfg.lsuv_m_2, wandb_cfg.lsuv_m_3)\n",
    "\n",
    "    cfg.model.model_configs[0]['m'] = [m]*(len(cfg.model.model_configs[0]['hidden_layers']) - 1) + [1.]\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    out_features = ground_truth.shape[-1]\n",
    "    model = instantiate(cfg[\"model\"], out_features=out_features)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    model = splitnet_lsuv_init(model, model_input, multipliers=lsuv_multipliers, verbose=False)\n",
    "    model, best_psnr = _custom_train_seed(model, cfg, random_seed=cfg.random_seed[0])\n",
    "\n",
    "    print('best_psnr', best_psnr)\n",
    "    wandb.log({'last_psnr': best_psnr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea90ce-6de0-4b86-81b3-f324e139c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=_train_for_sweep, count=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed859a-b9d5-4049-8a48-0cc253c5f6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522e12-86c3-4da4-963f-3eece2b89d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8bfd4-e4f0-4a8b-ad3e-7199804dc8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623866b-8e42-48d5-8210-927aa92b8cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
