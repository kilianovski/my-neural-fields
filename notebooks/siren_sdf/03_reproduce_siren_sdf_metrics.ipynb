{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0416d8-5aad-4de1-bdf0-285529954d0b",
   "metadata": {},
   "source": [
    "The goal of this notebook is to reproduce results from work: https://github.com/vsitzmann/siren on SDF task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43955b0-d0ae-43e9-9ca6-381a067003b4",
   "metadata": {},
   "source": [
    "Citation from paper:\n",
    "- Data: In paper the show results on Thai statue from the The Stanford 3D Scanning Repository.\n",
    "- Architecture: We use the same 5-layer SIREN MLP for all experiments on SDF, using 256 units in each layer for the statue and 1024 units in each layer for the room.\n",
    "- Hyperparameters: We train for 50,000 iterations, and **at each iteration fit on every voxel** of the volume. We use the Adam optimizer with a learning rate of 1 × 10−4 for all experiments. \n",
    "- We train for 50,000 iterations requiring approximately 6h hours to fit and evaluate a SIREN.\n",
    "- SIREN converge already very well after around 5,000-7,000 iterations.\n",
    "\n",
    "![image.png](screenshots/image_2023-04-26_14-14-03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fc17c1-94e8-41de-ae7a-7f6eaba1cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 26 12:25:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   69C    P8    20W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   77C    P0    72W /  70W |  14047MiB / 15360MiB |     61%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   2158634      C                                   14045MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfac8737-d51c-453d-97c9-5717097b1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f2e64a-84ff-470d-95e1-2eab7d2d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "\n",
    "try:\n",
    "    import lovely_tensors as lt\n",
    "except:\n",
    "    ! pip install --upgrade lovely-tensors\n",
    "    import lovely_tensors as lt\n",
    "    \n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92aebcd9-30cd-4c28-b283-806dad5b675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /app/notebooks/siren_sdf/checkpoints/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7644209f-15fc-4746-a838-ffd313519864",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    \"wandb_project\": \"siren_sdf\",\n",
    "    \"experiment_name\": \"thai_statue_baseline\",\n",
    "    \"logging\": True,\n",
    "    \"point_cloud_path\": \"data/thai_statue.xyz\",\n",
    "    \"batch_size\": 25_000,\n",
    "    \"clip_grad\": True,\n",
    "    \"checkpoint_dir\": Path('checkpoints/'),\n",
    "    \"save_ckpt_freq\": 10_000,\n",
    "    \"vis_freq\": 2_500,\n",
    "    \"epochs\": 10000,\n",
    "    \n",
    "    \"lr\": 1e-4,\n",
    "    \"iteration_on_stop\": 50_000,\n",
    "    \"hidden_features\": 256,\n",
    "    \"num_hidden_layers\": 5,\n",
    "    \"net_type\": 'sine',\n",
    "}\n",
    "\n",
    "config[\"checkpoint_dir\"].mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb866fa-7570-4f99-b3b6-5d4f042be7e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eeae049-7a4c-4f66-a5cb-373421427ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image==0.20.0 scikit-video==1.1.11 opencv-python==4.7.0.72 cmapy==0.6.6 ConfigArgParse==1.5.3 plyfile==0.9 -q\n",
    "# !pip uninstall scipy -y; pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99878c34-3e1a-4e25-acb4-e6ef97630795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.dataio as dataio\n",
    "from torch.utils.data import DataLoader\n",
    "from src.utils import get_sdf_summary\n",
    "from src.sdf_meshing import create_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42596fdd-47f6-406e-8ac0-06dd8f6e12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud\n",
      "Finished loading point cloud\n"
     ]
    }
   ],
   "source": [
    "sdf_dataset = dataio.PointCloud(config['point_cloud_path'], on_surface_points=config['batch_size'])\n",
    "dataloader = DataLoader(sdf_dataset, shuffle=True, batch_size=1, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0dc356-6a33-4f32-a1bb-ef15522583e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.nn_modules import SingleBVPNet\n",
    "    \n",
    "model = SingleBVPNet(type=config['net_type'], in_features=3, hidden_features=config['hidden_features'], num_hidden_layers=config['num_hidden_layers']).to(config['device'])\n",
    "# if config.get('load_from_checkpoint_path') is not None and Path(config['load_from_checkpoint_path']).exists():\n",
    "#     model.load_state_dict(torch.load(config['load_from_checkpoint_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab120c85-f958-4d33-8339-b0041159fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loss_functions import sdf\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=config['lr'], params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85448d85-985e-4dac-9b40-6a9a60d8c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnerlfield\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebooks/siren_sdf/wandb/run-20230426_122559-u9dkw7k0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nerlfield/siren_sdf/runs/u9dkw7k0\" target=\"_blank\">thai_statue_baseline</a></strong> to <a href=\"https://wandb.ai/nerlfield/siren_sdf\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "if config['logging']:\n",
    "    run = wandb.init(project=config[\"wandb_project\"], name=config[\"experiment_name\"], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90564649-6dbb-483a-9d89-ca6256d72f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008492231369018555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e404ba5964b35bc5fbe630e93cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/notebooks/siren_sdf/src/utils.py:73: UserWarning: No contour levels were found within the data range.\n",
      "  ax.contour(sample, levels=[0], colors='k', linewidths=0.3)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "iteration = 0\n",
    "for epoch in (pbar := tqdm(range(int(config['epochs'])))):\n",
    "    for step, (model_input, gt) in enumerate(dataloader):\n",
    "        model_input = {key: value.to(config['device']) for key, value in model_input.items()}\n",
    "        gt = {key: value.to(config['device']) for key, value in gt.items()}\n",
    "        \n",
    "        model_output = model(model_input)\n",
    "        losses = sdf(model_output, gt)\n",
    "        \n",
    "        train_loss = 0.\n",
    "        for loss_name, loss in losses.items():\n",
    "            single_loss = loss.mean()\n",
    "            train_loss += single_loss\n",
    "                \n",
    "        if config['logging']:\n",
    "            wandb.log({\n",
    "                \"sdf\": losses['sdf'].item(),\n",
    "                \"inter\": losses['inter'].item(),\n",
    "                \"normal_constraint\": losses['normal_constraint'].item(),\n",
    "                \"grad_constraint\": losses['grad_constraint'].item(),\n",
    "                \"train_loss\": train_loss.item()\n",
    "            })\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "\n",
    "        if config['clip_grad']:\n",
    "            if isinstance(config['clip_grad'], bool):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad'])\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iteration % config['vis_freq'] == 0 and config['logging']:\n",
    "            sdf_summary = get_sdf_summary(model, model_input, gt, model_output)\n",
    "            wandb.log({\n",
    "                \"xy_sdf_slice\": wandb.Image(sdf_summary['xy_sdf_slice']),\n",
    "                \"xz_sdf_slice\": wandb.Image(sdf_summary['xz_sdf_slice']),\n",
    "                \"yz_sdf_slice\": wandb.Image(sdf_summary['yz_sdf_slice'])\n",
    "            })\n",
    "            \n",
    "        if iteration % config['save_ckpt_freq'] == 0:\n",
    "            torch.save(model.state_dict(), config['checkpoint_dir'] / f\"{config['wandb_project']}_{config['experiment_name']}_{epoch}_{iteration}.pth\")\n",
    "        \n",
    "        pbar.set_description(f' => Loss: {train_loss.item():.3f}')\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        if iteration > config['iteration_on_stop']:\n",
    "            break\n",
    "    if iteration > config['iteration_on_stop']:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e94e95a-dc72-4636-bc4d-9b24d77b3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), config['checkpoint_dir'] / f\"{config['wandb_project']}_{config['experiment_name']}_{epoch}_{iteration}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03bf65a9-727a-4fe6-b370-7d3fd13eff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('checkpoints/siren_sdf_thai_statue_baseline_251_50001.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_10_mult_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_100_20000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_150_30000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_10mult_normal_init_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_201_40000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_50_10000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_5mult_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_baseline_251_50000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_5mult_50_10000.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_normal_init_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_0_0.pth'),\n",
       " Path('checkpoints/siren_sdf_thai_statue_splitact_baseline_with_siren_init_0_0.pth')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in config['checkpoint_dir'].ls()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef83b38-b313-40cd-8448-96148d6aff76",
   "metadata": {},
   "source": [
    "# Save to mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef95b72-ab59-4a59-8a89-fed6db796e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ce52feb-d1f3-4853-8e0b-32db234be729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn_modules import SingleBVPNet\n",
    "\n",
    "class SDFDecoder(torch.nn.Module):\n",
    "    def __init__(self, config, ckpt_path=None):\n",
    "        super().__init__()\n",
    "        # Define the model.\n",
    "        self.model = SingleBVPNet(type=config['net_type'], in_features=3, hidden_features=config['hidden_features'], num_hidden_layers=config['num_hidden_layers'])\n",
    "        if ckpt_path is not None:\n",
    "            self.model.load_state_dict(torch.load(ckpt_path))\n",
    "        self.model = self.model.to(config['device'])\n",
    "\n",
    "    def forward(self, coords):\n",
    "        model_in = {'coords': coords}\n",
    "        return self.model(model_in)['model_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73824c9a-73b1-44dd-bab0-88a9b91cda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = SDFDecoder(config, Path('checkpoints/siren_sdf_thai_statue_baseline_50_10000.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dbf5d01-f473-4d06-9ef1-3525c5149522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "262144\n",
      "524288\n",
      "786432\n",
      "1048576\n",
      "1310720\n",
      "1572864\n",
      "1835008\n",
      "2097152\n",
      "2359296\n",
      "2621440\n",
      "2883584\n",
      "3145728\n",
      "3407872\n",
      "3670016\n",
      "3932160\n",
      "4194304\n",
      "4456448\n",
      "4718592\n",
      "4980736\n",
      "5242880\n",
      "5505024\n",
      "5767168\n",
      "6029312\n",
      "6291456\n",
      "6553600\n",
      "6815744\n",
      "7077888\n",
      "7340032\n",
      "7602176\n",
      "7864320\n",
      "sampling takes: 5.443153\n",
      "torch.Size([200, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "create_mesh(decoder, config['experiment_name'], device=config['device'], N=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a5a1f-6d13-48ca-a552-06682f379a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
